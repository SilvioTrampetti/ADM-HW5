{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(data):\n",
    "    data=data.strip().split(\"\\t\")\n",
    "    return((data[0],data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sparktext1.map(splitting).groupByKey().map(lambda x : (x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "graph = defaultdict(list)\n",
    "\n",
    "list1= list()\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "        for line in f:\n",
    "            list1 = line.strip().split(\"\\t\")\n",
    "            if list1[0] in graph.keys():\n",
    "                graph[list1[0]].append(list1[1])\n",
    "            else:\n",
    "                graph[list1[0]]=[list1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the edges of the graph\n",
    "edges = []\n",
    "for e in graph:\n",
    "    a = graph[e]\n",
    "    for i in range(len(a)):\n",
    "        edges.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges) #2645247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph.keys())\n",
    "#FOR SURE DIRECTED GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= list()\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "        for line in f:\n",
    "            list1.append(line.strip().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the nodes of the graph\n",
    "nodes = []\n",
    "for e in list1:\n",
    "    nodes.append(e[0])\n",
    "    nodes.append(e[1])\n",
    "nodes=set(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes) #461193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Node Degree\n",
    "count = 0\n",
    "for lst in graph.values():\n",
    "    count += len(lst)\n",
    "avgNodeDegree = count/len(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgNodeDegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Density\n",
    "dense = len(edges)/(len(nodes)*(len(nodes)-1))\n",
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(nodes)*(len(nodes)-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/atefe/Desktop/ADM-HW5/dictionary.json\",\"w\") as d:\n",
    "    json.dump(graph,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.DiGraph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the graph\n",
    "\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "    for line in f:\n",
    "        list1 = line.strip().split(\"\\t\")\n",
    "        G.add_node(list1[0])\n",
    "        G.add_edge(list1[0],list1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding attribute 'Category' to each node of the graph\n",
    "\n",
    "for i in G:\n",
    "    G.node[i]['Category']=[]\n",
    "    \n",
    "from collections import defaultdict\n",
    "category_dict = defaultdict()\n",
    "\n",
    "with open(\"wiki-topcats-categories.txt\", \"r\") as f:\n",
    "    lst2=G.nodes()\n",
    "    for line in f:\n",
    "        cat_list = line.strip().split(\";\")\n",
    "        category = cat_list[0][9:]\n",
    "        lst = cat_list[1].strip().split(\" \")\n",
    "        if len(lst) > 3500:   \n",
    "            \n",
    "            lst1=[el for el in lst if el in lst2]\n",
    "            category_dict[category] = lst1\n",
    "\n",
    "#Assign attributes to each node\n",
    "for cat in category_dict:\n",
    "    lst=category_dict[cat]\n",
    "    for e in lst:\n",
    "        if e in G:\n",
    "            G.node[e]['Category'].append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.node['52']['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"category_dict.json\",\"w\") as d:\n",
    "    json.dump(category_dict,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"category_dict.json\",\"r\") as d:\n",
    "    category_dict = json.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = list(category_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''category_list = list(category_dict.keys())\n",
    "\n",
    "import random\n",
    "n = random.randint(0, len(category_list))\n",
    "\n",
    "input_category = category_list[n] \n",
    "auxiliary_list = category_list\n",
    "auxiliary_list.remove(input_category)\n",
    "#for stringa in aux_list:\n",
    "    #Bfs(category_list[n], stringa)\n",
    "target_category = auxiliary_list[random.randint(0, len(auxiliary_list))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_category='Living_people'\n",
    "#target_category1='Major_League_Baseball_pitchers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_category='Indian_films'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tnrange, tqdm_notebook\n",
    "#for i in tnrange(100):\n",
    " #   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from numba import autojit\n",
    "import threading\n",
    "\n",
    "\n",
    "@autojit\n",
    "def distance(G, C0, C1):\n",
    "   \n",
    "    c0 = category_dict[C0][0:50]\n",
    "    #c1 = set(category_dict[C1])\n",
    "    #c1 = c1.difference(c0)\n",
    "    #value=len(c0)\n",
    "    #c0 = list(c0)\n",
    "    #c1 = list(c1)\n",
    "    #with tqdm(total=value) as pbar:\n",
    "    shortest_paths = list()\n",
    "    for i in tnrange(len(c0)):\n",
    "        \n",
    "    #for i in range(len(c0)):\n",
    "        root=c0[i]\n",
    "        #pbar.write(\"proccesed: %d\"  %c0)\n",
    "        #pbar.update(1)\n",
    "        step = 0\n",
    "        seen=set([root])\n",
    "        queue=collections.deque([(root,step)])\n",
    "        while queue:\n",
    "            vertex=queue.popleft()\n",
    "            \n",
    "            if C1 in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths.append(step)    \n",
    "            neighbors1 = list(G[vertex[0]])\n",
    "            \n",
    "            step=vertex[1]+1\n",
    "            if neighbors1 == []:\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            for i in neighbors1:\n",
    "                if i not in seen:\n",
    "                    queue.append((i,step))                    \n",
    "                    seen.add(i)\n",
    "            \n",
    "    array = np.array(sorted(shortest_paths))\n",
    "    m = np.median(array)\n",
    "    return (C1, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for key in sp:\n",
    "    l = len(sp[key])\n",
    "    il = 20#len(category_dict[input_category])\n",
    "    if l == il:\n",
    "        continue\n",
    "    else:\n",
    "        diff = abs(il - l)\n",
    "        aux_l = [math.inf for i in range(diff)]\n",
    "        sp[key] = sp[key] + aux_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(category_dict['Indian_films'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d=distance(G, input_category, target_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from numba import autojit\n",
    "import threading\n",
    "\n",
    "\n",
    "#@autojit\n",
    "def distance_graph(G, C0, C1):\n",
    "   \n",
    "    c0 = category_dict[C0][0:2000]\n",
    "\n",
    "    #with tqdm(total=value) as pbar:\n",
    "    shortest_paths_1 = list()\n",
    "    shortest_paths_2 = list()\n",
    "    shortest_paths_3 = list()\n",
    "    shortest_paths_4 = list()\n",
    "\n",
    "    for i in tnrange(len(c0)):\n",
    "        \n",
    "    #for i in range(len(c0)):\n",
    "        root=c0[i]\n",
    "        #pbar.write(\"proccesed: %d\"  %c0)\n",
    "        #pbar.update(1)\n",
    "        step = 0\n",
    "        seen=set([root])\n",
    "        queue=collections.deque([(root,step)])\n",
    "        while queue:\n",
    "            vertex=queue.popleft()\n",
    "            \n",
    "            \n",
    "            if C1[0] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_1.append(step)\n",
    "                 \n",
    "            elif C1[1] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_2.append(step)\n",
    "                   \n",
    "            \n",
    "            elif C1[2] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_3.append(step)\n",
    "                  \n",
    "            elif C1[3] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_4.append(step)\n",
    "                    \n",
    "            \n",
    "            neighbors1 = list(G[vertex[0]])\n",
    "            \n",
    "            step=vertex[1]+1\n",
    "            if neighbors1 == []:\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            for i in neighbors1:\n",
    "                if i not in seen:\n",
    "                    queue.append((i,step))                    \n",
    "                    seen.add(i)\n",
    "                    \n",
    "    for i in range(len(C1)):\n",
    "        lc = len(category_dict[C1[i]])\n",
    "        \n",
    "        if len(eval('shortest_paths_%d'% (i+1))) != lc:\n",
    "            \n",
    "            diff = abs(len(eval('shortest_paths_%d'% (i+1))) - lc*len(c0))\n",
    "            #print(lc, diff, len(eval('shortest_paths_%d'% (i+1))))\n",
    "            aux_l = [math.inf for i in range(diff)]\n",
    "            eval(\"shortest_paths_{}\".format(i+1)).extend(aux_l)\n",
    "    \n",
    "    return [(C1[0], np.median(np.array(sorted(shortest_paths_1)))), (C1[1], np.median(np.array(sorted(shortest_paths_2)))),\n",
    "           (C1[2], np.median(np.array(sorted(shortest_paths_3)))), (C1[3], np.median(np.array(sorted(shortest_paths_4))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ci = distance_graph(G, input_category,lst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_list = list(category_dict.keys())\n",
    "auxiliary_list.remove(input_category)\n",
    "i=0\n",
    "lst=[]\n",
    "while i < 16:\n",
    "    lst.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_2=[]\n",
    "while i<32:\n",
    "    lst_2.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Asteroids_named_for_people',\n",
       "  'English-language_albums',\n",
       "  'English_television_actors',\n",
       "  'British_films'],\n",
       " ['English-language_films',\n",
       "  'American_films',\n",
       "  'Fellows_of_the_Royal_Society',\n",
       "  'People_from_New_York_City'],\n",
       " ['American_Jews',\n",
       "  'American_television_actors',\n",
       "  'American_film_actors',\n",
       "  'Debut_albums'],\n",
       " ['Black-and-white_films',\n",
       "  'Year_of_birth_missing',\n",
       "  'Place_of_birth_missing_(living_people)',\n",
       "  'Article_Feedback_Pilot']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "def threadGraph(lst):\n",
    "    res_list.append(distance_graph(G,input_category, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for a in range(2,4):\n",
    "    t = threading.Thread(name = a, target = threadGraph,\n",
    "                       args = [lst[a]])\n",
    "    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Graphdf=pd.DataFrame()\n",
    "\n",
    "for i in res_list:\n",
    "    Graphdf1=pd.DataFrame(i)\n",
    "    Graphdf=Graphdf.append(Graphdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphdf.to_csv(\"Graphdf1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list1 = []\n",
    "def threadGraph1(lst):\n",
    "    res_list1.append(distance_graph(G,input_category, lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d0077458048909aba200313415f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08948c6ffd424e10a80108730a689cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcda437e795d40e1aa84d85d151d7334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e28c60eb346668452e367e35bfe07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threads = []\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph1,\n",
    "                       args = [lst_2[a]])\n",
    "    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('English-language_films', 6.0),\n",
       "  ('American_films', inf),\n",
       "  ('Fellows_of_the_Royal_Society', 8.0),\n",
       "  ('People_from_New_York_City', 7.0)],\n",
       " [('Black-and-white_films', 7.0),\n",
       "  ('Year_of_birth_missing', inf),\n",
       "  ('Place_of_birth_missing_(living_people)', 8.0),\n",
       "  ('Article_Feedback_Pilot', 6.0)],\n",
       " [('Asteroids_named_for_people', inf),\n",
       "  ('English-language_albums', 7.0),\n",
       "  ('English_television_actors', 6.0),\n",
       "  ('British_films', 6.0)],\n",
       " [('American_Jews', 7.0),\n",
       "  ('American_television_actors', 6.0),\n",
       "  ('American_film_actors', inf),\n",
       "  ('Debut_albums', 7.0)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Graphdf=pd.DataFrame()\n",
    "\n",
    "for i in res_list1:\n",
    "    Graphdf1=pd.DataFrame(i)\n",
    "    Graphdf=Graphdf.append(Graphdf1)\n",
    "Graphdf.to_csv(\"Graph3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_films</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fellows_of_the_Royal_Society</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Article_Feedback_Pilot</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_Jews</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0         1\n",
       "0                  English-language_films  6.000000\n",
       "1                          American_films       inf\n",
       "2            Fellows_of_the_Royal_Society  8.000000\n",
       "3               People_from_New_York_City  7.000000\n",
       "0                   Black-and-white_films  7.000000\n",
       "1                   Year_of_birth_missing       inf\n",
       "2  Place_of_birth_missing_(living_people)  8.000000\n",
       "3                  Article_Feedback_Pilot  6.000000\n",
       "0              Asteroids_named_for_people       inf\n",
       "1                 English-language_albums  7.000000\n",
       "2               English_television_actors  6.000000\n",
       "3                           British_films  6.000000\n",
       "0                           American_Jews  7.000000\n",
       "1              American_television_actors  6.000000\n",
       "2                    American_film_actors       inf\n",
       "3                            Debut_albums  7.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graphdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second part of category_list but the input list\n",
    "i=0\n",
    "lst_2=[]\n",
    "while i < 16:\n",
    "    lst_2.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph,\n",
    "                       args = [lst_2[a]])    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = []\n",
    "for lst in res_list:    \n",
    "    v = np.median(np.array(sorted(lst)))\n",
    "    ms.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''h = []\n",
    "shortpath=list()\n",
    "for a0 in category_dict['English_footballers']:\n",
    "    \n",
    "    for a1 in category_dict['The_Football_League_players']:\n",
    "        shortpath.append(Bfs(G,a0,a1))\n",
    "    m = np.median\n",
    "    h.heapqpush((m, ( cat2)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#@autojit\n",
    "def distance_graph1(G, C0, C1):\n",
    "   \n",
    "    c0 = category_dict[C0][0:2000]\n",
    "    #for i in range(len(C1)):\n",
    "        #exec(f'shortest_paths_{i}=[]')\n",
    "\n",
    "    #with tqdm(total=value) as pbar:\n",
    "    shortest_paths_1 = list()\n",
    "    shortest_paths_2 = list()\n",
    "    #shortest_paths_3 = list()\n",
    "    #shortest_paths_4 = list()\n",
    "\n",
    "    for i in tnrange(len(c0)):\n",
    "        \n",
    "    #for i in range(len(c0)):\n",
    "        root=c0[i]\n",
    "        #pbar.write(\"proccesed: %d\"  %c0)\n",
    "        #pbar.update(1)\n",
    "        step = 0\n",
    "        seen=set([root])\n",
    "        queue=collections.deque([(root,step)])\n",
    "        while queue:\n",
    "            vertex=queue.popleft()\n",
    "            \n",
    "            \n",
    "            if C1[0] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_1.append(step)\n",
    "                 \n",
    "            elif C1[1] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    shortest_paths_2.append(step)\n",
    "                   \n",
    "            \n",
    "            #elif C1[2] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    #shortest_paths_3.append(step)\n",
    "                  \n",
    "            #elif C1[3] in G.node[vertex[0]]['Category'] and C0 not in G.node[vertex[0]]['Category']:\n",
    "                    #shortest_paths_4.append(step)\n",
    "                    \n",
    "            \n",
    "            neighbors1 = list(G[vertex[0]])\n",
    "            \n",
    "            step=vertex[1]+1\n",
    "            if neighbors1 == []:\n",
    "                continue\n",
    "              \n",
    "            \n",
    "            for i in neighbors1:\n",
    "                if i not in seen:\n",
    "                    queue.append((i,step))                    \n",
    "                    seen.add(i)\n",
    "                    \n",
    "    for i in range(len(C1)):\n",
    "        lc = len(category_dict[C1[i]])\n",
    "        \n",
    "        if len(eval('shortest_paths_%d'% (i+1))) != lc:\n",
    "            \n",
    "            diff = abs(len(eval('shortest_paths_%d'% (i+1))) - lc*len(c0))\n",
    "            #print(lc, diff, len(eval('shortest_paths_%d'% (i+1))))\n",
    "            aux_l = [math.inf for i in range(diff)]\n",
    "            eval(\"shortest_paths_{}\".format(i+1)).extend(aux_l)\n",
    "    \n",
    "    return [(C1[0], np.median(np.array(sorted(shortest_paths_1)))), (C1[1], np.median(np.array(sorted(shortest_paths_2))))]\n",
    "           #(C1[2], np.median(np.array(sorted(shortest_paths_3)))), #(C1[3], np.median(np.array(sorted(shortest_paths_4))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73db61b1b504f9c9418ae4e6872bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d=distance_graph1(G,input_category,['American_military_personnel_of_World_War_II', 'Windows_games'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Graphdf=pd.DataFrame()\n",
    "Graphdf=Graphdf.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graphdf.to_csv(\"Graph2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
