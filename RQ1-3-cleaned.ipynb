{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = f.graph_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['401135', '1069112', '1163551']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['52']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1060396', '1061304', '1062611', '1066969', '1069008', '1069113', '1069258', '1069275', '1656982']\n"
     ]
    }
   ],
   "source": [
    "print(graph['1069112'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The graph is not undirected because the node 52 has edge with 1099112 and the reverse is not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the edges of the graph\n",
    "edges = []\n",
    "for e in graph:\n",
    "    a = graph[e]\n",
    "    for i in range(len(a)):\n",
    "        edges.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges) #2645247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428957"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.keys())\n",
    "#FOR SURE DIRECTED GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= list()\n",
    "with open(\"wiki-topcats-reduced.txt\") as f:\n",
    "        for line in f:\n",
    "            list1.append(line.strip().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to figure out the nodes of the graph\n",
    "nodes = []\n",
    "for e in list1:\n",
    "    nodes.append(e[0])\n",
    "    nodes.append(e[1])\n",
    "nodes=set(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes) #461193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Node Degree\n",
    "count = 0\n",
    "for lst in graph.values():\n",
    "    count += len(lst)\n",
    "avgNodeDegree = count/len(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1666950300379755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgNodeDegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2436602635647606e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Density\n",
    "dense = len(edges)/(len(nodes)*(len(nodes)-1))\n",
    "dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, category_dict=f.create_graph_and_dict()\n",
    "category_list = list(category_dict.keys())\n",
    "input_category='Indian_films'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below created the list of lists for the first 16 categories \n",
    "auxiliary_list = list(category_dict.keys())\n",
    "auxiliary_list.remove(input_category)\n",
    "i=0\n",
    "lst=[]\n",
    "while i < 16:\n",
    "    lst.append(auxiliary_list[i:i+4])\n",
    "    i+=4\n",
    "\n",
    "#this is the next list\n",
    "lst_2=[]\n",
    "while i<32:\n",
    "    lst_2.append(auxiliary_list[i:i+4])\n",
    "    i+=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Threads\n",
    "#### Below multi-threading is used to facilitate the execution of the BFS algorithm, in order to find the distances between the category that we chosen and the others. \n",
    "#### As the input was too large for BFS function . Multithreading has been used for running the same method for different categories at the same time, in order to obtain fast result instead of run each time the method for one category. Four threads are created to access to the BFS function.  Each time that the function is called it computes four categories (we decided this number for avoiding the Memory Error and to overload too much each thread.) The same for the procedure used for calling threads: we decided to call four thread per procedure for the same reason. \n",
    "\n",
    "#### res list was the resources that keep all the output of threads. As soon as the thread finished, the res list has been updated.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "def threadGraph(lst):\n",
    "    res_list.append(f.distance_graph(G,input_category, lst))\n",
    "\n",
    "threads = []\n",
    "#four threads are created here\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph1,\n",
    "                       args = [lst_2[a]])\n",
    "    \n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "Graphdf=pd.DataFrame()\n",
    "for i in res_list1:\n",
    "    Graphdf1=pd.DataFrame(i)\n",
    "    Graphdf=Graphdf.append(Graphdf1)\n",
    "Graphdf.to_csv(\"Graph1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_films</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fellows_of_the_Royal_Society</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Article_Feedback_Pilot</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British_films</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_Jews</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0         1\n",
       "0                  English-language_films  6.000000\n",
       "1                          American_films       inf\n",
       "2            Fellows_of_the_Royal_Society  8.000000\n",
       "3               People_from_New_York_City  7.000000\n",
       "0                   Black-and-white_films  7.000000\n",
       "1                   Year_of_birth_missing       inf\n",
       "2  Place_of_birth_missing_(living_people)  8.000000\n",
       "3                  Article_Feedback_Pilot  6.000000\n",
       "0              Asteroids_named_for_people       inf\n",
       "1                 English-language_albums  7.000000\n",
       "2               English_television_actors  6.000000\n",
       "3                           British_films  6.000000\n",
       "0                           American_Jews  7.000000\n",
       "1              American_television_actors  6.000000\n",
       "2                    American_film_actors       inf\n",
       "3                            Debut_albums  7.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graphdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list1 = []\n",
    "def threadGraph1(lst):\n",
    "    res_list1.append(distance_graph(G,input_category, lst))\n",
    "\n",
    "threads = []\n",
    "for a in range(4):\n",
    "    t = threading.Thread(name = a, target = threadGraph,\n",
    "                       args = [lst_2[a]])    \n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('English-language_films', 6.0),\n",
       "  ('American_films', inf),\n",
       "  ('Fellows_of_the_Royal_Society', 8.0),\n",
       "  ('People_from_New_York_City', 7.0)],\n",
       " [('Black-and-white_films', 7.0),\n",
       "  ('Year_of_birth_missing', inf),\n",
       "  ('Place_of_birth_missing_(living_people)', 8.0),\n",
       "  ('Article_Feedback_Pilot', 6.0)],\n",
       " [('Asteroids_named_for_people', inf),\n",
       "  ('English-language_albums', 7.0),\n",
       "  ('English_television_actors', 6.0),\n",
       "  ('British_films', 6.0)],\n",
       " [('American_Jews', 7.0),\n",
       "  ('American_television_actors', 6.0),\n",
       "  ('American_film_actors', inf),\n",
       "  ('Debut_albums', 7.0)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the result is like below for each category the median shortest path\n",
    "res_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=f.distance_graph2(G,input_category,['American_military_personnel_of_World_War_II', 'Windows_games','Indian_films'])\n",
    "Graphdf=pd.DataFrame()\n",
    "Graphdf=Graphdf.append(d)\n",
    "Graphdf.to_csv(\"Graph3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Babas; font-size: 1.2em;\">\n",
    " <ul>\n",
    " <li>  We runned the previous algorithm that contains the Search of the Shortest Paths using threads for three times.\n",
    " This was due to the fact that data were big.\n",
    " Input given to the method: graph, input category, list with categories in order to find the shortest paths. \n",
    "</li>\n",
    "    <li>\n",
    "    Because we runned three times in different moments, we saved three lists with the results in this format:\n",
    " (Name of the Category, Rank with the input category with this category);\n",
    " </li>\n",
    "    <li>\n",
    " Thus, we merged all the categories with the ranks together.\n",
    "Below there is the Dataframe related to categories, sorted from the closest one until the furthest one by distance in order to rank categories.\n",
    "    </li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=pd.read_csv('Graphdf1.csv')\n",
    "dfg1 = pd.read_csv('Graphdf2.csv')\n",
    "dfg2 = pd.read_csv('Graph3.csv')\n",
    "dfg=dfg.reset_index(drop=True)\n",
    "dfg = dfg.rename(columns={\"0\": \"Category\", \"1\": \"Distance\"})\n",
    "dfg = dfg.sort_values(by='Distance')\n",
    "dfg = dfg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.to_csv('ranking_table.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=pd.read_csv('ranking_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Babas; font-size: 1.2em;\">\n",
    "\n",
    "Last point: We want to keep an information, score, into each node. First, we initialized every node as a negative value, in order to make a check (if we still didn't pass throught that node it will be still a negative number, but if there are no in edges this information will be 0). \n",
    "\n",
    "This initialization will be done into G, our original graph.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = f.steps(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import autojit, prange\n",
    "list1 = []\n",
    "@autojit\n",
    "def graphscore(e):\n",
    "    score_dict={}\n",
    "    score_dict['Node']=e\n",
    "    score_dict['Score']=G.node[e]['score']\n",
    "    return(score_dict)\n",
    "for e in G:\n",
    "    list1.append(graphscore(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscore=pd.DataFrame(list1)\n",
    "dfscore = dfscore.sort_values(by='Score', ascending=False)\n",
    "dfscore.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
